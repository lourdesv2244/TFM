# TFM
# Ticket Classification & Assignment MVP

# Resumen
El presente Trabajo de Fin de M√°ster (TFM) tiene como objetivo entregar un Producto M√≠nimo Viable (MVP) que consiste en un prototipo inicial para la clasificaci√≥n y asignaci√≥n autom√°tica de tickets t√©cnicos en el equipo de soporte de Data & Analytics MAZ. Esta propuesta responde a la creciente demanda de soluciones operativas que permitan gestionar de manera eficiente el volumen de solicitudes recibidas, caracterizadas por un alto grado de complejidad t√©cnica y una nomenclatura espec√≠fica del dominio, lo que exige una clasificaci√≥n precisa y una asignaci√≥n √≥ptima a agentes especializados.

La metodolog√≠a se bas√≥ en la combinaci√≥n de t√©cnicas de aprendizaje autom√°tico supervisado y procesamiento del lenguaje natural. Inicialmente, se realiz√≥ una recolecci√≥n y etiquetado manual de 500 tickets reales, distribuidos en seis categor√≠as definidas por expertos. Posteriormente, se implement√≥ un preprocesamiento ling√º√≠stico especializado, con normalizaci√≥n, lematizaci√≥n y conservaci√≥n de t√©rminos t√©cnicos clave. Se probaron diversos algoritmos tradicionales (Random Forest, SVM, Gradient Boosting), as√≠ como una red neuronal profunda y un modelo BERT ajustado mediante fine-tuning. A partir de este √∫ltimo se desarroll√≥ BERT con tokens, una versi√≥n optimizada que incorpora tokens especiales, capa de atenci√≥n personalizada y generaci√≥n de explicaciones autom√°ticas.

Los resultados muestran que BERT con tokens alcanza una precisi√≥n del 92,1‚ÄØ% en clasificaci√≥n t√©cnica, mejorando en m√°s de 5 puntos porcentuales respecto a BERT est√°ndar (86,7‚ÄØ%) y acerc√°ndose al rendimiento de los modelos tradicionales m√°s precisos (93,4‚ÄØ%), con la ventaja a√±adida de ofrecer explicaciones interpretables sobre cada decisi√≥n. Finalmente, el sistema se integr√≥ en un flujo automatizado que no solo clasifica el ticket, sino que asigna din√°micamente al agente √≥ptimo en funci√≥n de su especialidad y carga de trabajo. Se concluye que la arquitectura propuesta representa una soluci√≥n robusta, explicable y lista para su incorporaci√≥n al proceso de soporte t√©cnico de D&A.

Keywords: Aprendizaje autom√°tico supervisado, Procesamiento del lenguaje natural (PLN), Red neuronal profunda, BERT, Fine-tuning, BERT con tokens, Tokens especiales, Clasificaci√≥n y asignaci√≥n autom√°tica, Modelos tradicionales (Random Forest, SVM, Gradient Boosting). Producto M√≠nimo Viable (MVP), Prototipo inicial, Recolecci√≥n de tickets reales, Etiquetado manual, Preprocesamiento ling√º√≠stico, Normalizaci√≥n, Lematizaci√≥n.

Este repositorio contiene el **Producto M√≠nimo Viable (MVP)** de una herramienta autom√°tica para la clasificaci√≥n y asignaci√≥n de tickets t√©cnicos, desarrollada en Python y dise√±ada para integrarse f√°cilmente con flujos basados en Excel o plataformas como ServiceNow.



## üìÇ Estructura del repositorio
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ sample_tickets.xlsx         # Ejemplo de archivo de entrada
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ tokenizer/                  # Tokenizer de Transformer (p. ej. BERT)
‚îÇ   ‚îî‚îÄ‚îÄ classifier/                 # Pesos del modelo de clasificaci√≥n
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ classify_assign.py          # Script principal de clasificaci√≥n y asignaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py            # M√≥dulo de preprocesamiento (CoreNLP + spaCy)
‚îÇ   ‚îú‚îÄ‚îÄ model.py                    # Definici√≥n del pipeline de Transformer
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                    # Funciones auxiliares (I/O, Excel, configuraci√≥n)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ exploration.ipynb           # An√°lisis exploratorio y pruebas interactivas
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                       # Documentaci√≥n principal




## üöÄ Instalaci√≥n

1. **Clona el repositorio**
   ```bash
   git clone https://github.com/tu-usuario/ticket-mvp.git
   cd ticket-mvp

2. **Crea un entorno virtual (recomendado)**
   ```bash
   python3.11 -m venv .venv
   source .venv/bin/activate    # macOS/Linux
   .venv\Scripts\activate       # Windows

3. **Instala las dependencias**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt

4. **Descarga el modelo preentrenado Copia los pesos del tokenizer y el clasificador en models/tokenizer/ y models/classifier/ respectivamente. Si usas un modelo de Hugging Face, por ejemplo BERT fine-tuned:**
   ```bash
   mkdir -p models/tokenizer models/classifier
   cd models/tokenizer
   git clone https://huggingface.co/tu-usuario/bert-tokenizer.git .
   cd ../classifier
   git clone https://huggingface.co/tu-usuario/bert-classifier.git .



## üéØ Uso
python src/classify_assign.py \
  --input data/sample_tickets.xlsx \
  --output results/assigned_tickets.xlsx \
  --config src/config.yaml

  ```bash
   mkdir -p models/tokenizer models/classifier
   cd models/tokenizer
   git clone https://huggingface.co/tu-usuario/bert-tokenizer.git .
   cd ../classifier
   git clone https://huggingface.co/tu-usuario/bert-classifier.git .
   python src/classify_assign.py \
        --input data/sample_tickets.xlsx \
        --output results/assigned_tickets.xlsx \
        --config src/config.yaml


* --input: Ruta al archivo Excel que contiene los tickets sin procesar.
* --output: Ruta donde se generar√° el archivo con categor√≠a y agente asignado.
* --config: Opcional, archivo YAML con par√°metros de umbral, reglas de asignaci√≥n y estructura de columnas.



‚öôÔ∏è Configuraci√≥n

El archivo src/config.yaml permite ajustar:

 ```bash
 preprocessing:
    nlp_pipeline: "spacy"    # "spacy" o "corenlp"
    lemmatize: true

 classification:
    model_path: "../models/classifier"
    threshold: 0.5
   
 assignment:
    strategy: "load_balance"  # "load_balance", "skill_match"
    agent_metadata: "../data/agents.json"


üìà Ejemplo de flujo

   1. Lectura y preprocesamiento ‚Äì Limpieza de texto, lematizaci√≥n y extracci√≥n de entidades con spaCy/CoreNLP.
   2. Clasificaci√≥n ‚Äì Transformer fine-tuned que devuelve categor√≠as (multietiqueta si est√° configurado).
   3. Asignaci√≥n ‚Äì Algoritmo basado en carga de trabajo, especialidad y reglas definidas en config.yaml.
   4. Exportaci√≥n ‚Äì Generaci√≥n de un archivo Excel con columnas:
       * Ticket ID
       * Texto original
       * Categor√≠as asignadas
       * Agente sugerido

     

üìö Recursos adicionales

   * Stanford CoreNLP ‚Äì Para extracci√≥n de entidades y an√°lisis sint√°ctico.
   * Hugging Face Transformers ‚Äì Para modelos BERT, GPT y fine-tuning.
   * spaCy ‚Äì Para tokenizaci√≥n y procesamiento r√°pido en Python.

     

ü§ù Contribuciones
1. **Haz un fork del repositorio**
2. **Crea una rama con tu mejora:**
   ```bash
   git checkout -b feature/nueva-caracteristica
3. **Haz tus commits:**
   ```bash
   git commit -m "A√±ade X funcionalidad"
4. **Env√≠a un pull request.**


   
üìÑ Licencia
Este proyecto est√° bajo la licencia MIT. 
