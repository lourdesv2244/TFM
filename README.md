# TFM
# Ticket Classification & Assignment MVP

Este repositorio contiene el **Producto MÃ­nimo Viable (MVP)** de una herramienta automÃ¡tica para la clasificaciÃ³n y asignaciÃ³n de tickets tÃ©cnicos, desarrollada en Python y diseÃ±ada para integrarse fÃ¡cilmente con flujos basados en Excel o plataformas como ServiceNow.

---

## ğŸ“‚ Estructura del repositorio
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_tickets.xlsx         # Ejemplo de archivo de entrada
â”œâ”€â”€ models/
â”‚   â””â”€â”€ tokenizer/                  # Tokenizer de Transformer (p. ej. BERT)
â”‚   â””â”€â”€ classifier/                 # Pesos del modelo de clasificaciÃ³n
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ classify_assign.py          # Script principal de clasificaciÃ³n y asignaciÃ³n
â”‚   â”œâ”€â”€ preprocessing.py            # MÃ³dulo de preprocesamiento (CoreNLP + spaCy)
â”‚   â”œâ”€â”€ model.py                    # DefiniciÃ³n del pipeline de Transformer
â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares (I/O, Excel, configuraciÃ³n)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb           # AnÃ¡lisis exploratorio y pruebas interactivas
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â””â”€â”€ README.md                       # DocumentaciÃ³n principal


---

## ğŸš€ InstalaciÃ³n

1. **Clona el repositorio**
   ```bash
   git clone https://github.com/tu-usuario/ticket-mvp.git
   cd ticket-mvp

2. **Crea un entorno virtual (recomendado)**
   ```bash
   python3.11 -m venv .venv
   source .venv/bin/activate    # macOS/Linux
   .venv\Scripts\activate       # Windows

3. **Instala las dependencias**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt

4. **Descarga el modelo preentrenado Copia los pesos del tokenizer y el clasificador en models/tokenizer/ y models/classifier/ respectivamente. Si usas un modelo de Hugging Face, por ejemplo BERT fine-tuned:**
   ```bash
   mkdir -p models/tokenizer models/classifier
   cd models/tokenizer
   git clone https://huggingface.co/tu-usuario/bert-tokenizer.git .
   cd ../classifier
   git clone https://huggingface.co/tu-usuario/bert-classifier.git .


---

## ğŸ¯ Uso

python src/classify_assign.py \
  --input data/sample_tickets.xlsx \
  --output results/assigned_tickets.xlsx \
  --config src/config.yaml

--input: Ruta al archivo Excel que contiene los tickets sin procesar.
--output: Ruta donde se generarÃ¡ el archivo con categorÃ­a y agente asignado.
--config: Opcional, archivo YAML con parÃ¡metros de umbral, reglas de asignaciÃ³n y estructura de columnas.


âš™ï¸ ConfiguraciÃ³n

El archivo src/config.yaml permite ajustar:
preprocessing:
  nlp_pipeline: "spacy"              # "spacy" o "corenlp"
  lemmatize: true

classification:
  model_path: "../models/classifier"
  threshold: 0.5

assignment:
  strategy: "load_balance"           # "load_balance", "skill_match"
  agent_metadata: "../data/agents.json"


ğŸ“ˆ Ejemplo de flujo

    Lectura y preprocesamiento â€“ Limpieza de texto, lematizaciÃ³n y extracciÃ³n de entidades con spaCy/CoreNLP.

    ClasificaciÃ³n â€“ Transformer fine-tuned que devuelve categorÃ­as (multietiqueta si estÃ¡ configurado).

    AsignaciÃ³n â€“ Algoritmo basado en carga de trabajo, especialidad y reglas definidas en config.yaml.

    ExportaciÃ³n â€“ GeneraciÃ³n de un archivo Excel con columnas:

        Ticket ID

        Texto original

        CategorÃ­as asignadas

        Agente sugerido

        Score de confianza

ğŸ“š Recursos adicionales

    Stanford CoreNLP â€“ Para extracciÃ³n de entidades y anÃ¡lisis sintÃ¡ctico.

    Hugging Face Transformers â€“ Para modelos BERT, GPT y fine-tuning.

    spaCy â€“ Para tokenizaciÃ³n y procesamiento rÃ¡pido en Python.

ğŸ¤ Contribuciones

    Haz un fork del repositorio.

    Crea una rama con tu mejora:
    ```bash
    git checkout -b feature/nueva-caracteristica
